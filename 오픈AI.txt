## 간단요약
사용언어: 파이썬
데이터베이스: Qdrant DB
텍스트 임베딩 모델: BAAI/bge-m3
자연어 처리: GPT(모델: gpt-4o-mini)
                 사용이유: DB에 저장된 답변을 바탕으로, 일관되고 읽기 쉬운 자연어 형태로 깔끔하게 재정리해 제공하기 위해 GPT를 사용합니다.
비용: 질문 1번(질문 400글자 + 답변 400글자 기준)을 1000개 거래처 기준 하루 1개씩 30일 질문 = 15.75달러(1430원 환율 기준 22,522원)

1. 크로마DB 사용
 - Microsoft C++ Build Tools 설치
 - pip install chromadb

거리 < 1.0:
–❗️매우 높은 유사도. 문장 구조나 키워드, 의미가 거의 동일한 경우

1.0 ≤ 거리 < 1.2:
–👍높은 유사도. 같은 주제·뉘앙스를 공유하며, 핵심 개념이 일치하는 경우

1.2 ≤ 거리 < 1.4:
–⚖️중간 유사도. 관련은 있지만, 세부 내용이나 뉘앙스가 다소 다른 경우

거리 ≥ 1.4:
–❌낮은 유사도. 주제나 키워드가 크게 다르거나, 문맥이 거의 겹치지 않는 경우

#구조 
   ids= 키값
   documents= "Q: {질문}\nA: {답변}"
   "metadatas": {
      "SUBJT": "주제",
      "CTGRY": "카테고리",
      "QUEST": "질문",
      "ANSWR": "답변",
      "VENDR": "외부연계업체",
      "ACCLV": "접근권한",
      "HSPCD": "병원요양기호",
      "DBSDT": "디비인서트 시간"
    }

2. 비쥬얼 스튜디오 파이썬으로 코딩
 - AES256 암호화 설치 pip install cryptography


3. 임베딩 모델 BGE-m3 사용
- pip install sentence-transformers
- BGE-M3는 중국 베이징인공지능연구원(BAAI, Beijing Academy of Artificial Intelligence)에서 공개한 텍스트 임베딩 모델입니다.
- 자연어, 이미지, 오디오 등 다양한 입력 데이터를 고정된 크기의 숫자 벡터(vector)로 변환(transform)해 주는 모델
   유사도 검색: 문장 간 의미 유사도 비교(벡터 간 거리 계산)
   RAG(Retrieval-Augmented Generation): 벡터 검색으로 관련 문서를 찾아온 뒤, GPT 같은 생성 모델에 컨텍스트로 제공



